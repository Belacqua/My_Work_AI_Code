{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sqlalchemy import create_engine, text\n","from openai import OpenAI\n","import logging\n","from sklearn.metrics.pairwise import cosine_similarity\n","import asyncio\n","import os\n","\n","# Set up logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","class TaskCapabilityMapper:\n","    \"\"\"Maps RFQ tasks to capability subcategories using RAG approach\"\"\"\n","\n","    def __init__(self, db_config, api_key, embedding_model=\"text-embedding-3-small\", llm_model=\"gpt-4o\"):\n","        \"\"\"Initialize with database config and OpenAI API key\"\"\"\n","        self.db_config = db_config\n","        self.api_key = api_key\n","        self.embedding_model = embedding_model\n","        self.llm_model = llm_model\n","        self.client = OpenAI(api_key=api_key)\n","        self.engine = self._create_db_connection()\n","\n","    def _create_db_connection(self):\n","        \"\"\"Create database connection\"\"\"\n","        connection_string = f\"postgresql+psycopg://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['dbname']}\"\n","        return create_engine(connection_string)\n","\n","    def fetch_service_catalog(self):\n","        \"\"\"Fetch service catalog data with category context\"\"\"\n","        query = \"\"\"\n","        SELECT\n","            mcl.subcategory_id,\n","            mcl.subcategory_name,\n","            mcl.subcategory_description,\n","            cc.classification_name,\n","            cc.category_name,\n","            cc.category_description,\n","            cc.parent_naics\n","        FROM\n","            wbs.master_capability_list mcl\n","        JOIN\n","            references.capabilities_categories cc ON mcl.parent_category_id = cc.category_id\n","        \"\"\"\n","\n","        return pd.read_sql(query, self.engine)\n","\n","    def fetch_rfq_tasks(self, rfq_id=None):\n","        \"\"\"Fetch RFQ tasks that need to be mapped\"\"\"\n","        if rfq_id:\n","            query = \"\"\"\n","            SELECT\n","                rt.task_id,\n","                rt.task_text,\n","                rd.rfq_id,\n","                rm.rfq_number,\n","                rm.contract_title\n","            FROM\n","                rfq.rfq_tasks rt\n","            JOIN\n","                rfq.rfq_documents rd ON rt.document_id = rd.document_id\n","            JOIN\n","                rfq.rfq_metadata rm ON rd.rfq_id = rm.rfq_id\n","            WHERE\n","                rd.rfq_id = :rfq_id\n","            AND\n","                rt.task_id NOT IN (SELECT task_id FROM wbs.wbs_task_map)\n","            \"\"\"\n","            return pd.read_sql(query, self.engine, params={\"rfq_id\": rfq_id})\n","        else:\n","            query = \"\"\"\n","            SELECT\n","                rt.task_id,\n","                rt.task_text,\n","                rd.rfq_id,\n","                rm.rfq_number,\n","                rm.contract_title\n","            FROM\n","                rfq.rfq_tasks rt\n","            JOIN\n","                rfq.rfq_documents rd ON rt.document_id = rd.document_id\n","            JOIN\n","                rfq.rfq_metadata rm ON rd.rfq_id = rm.rfq_id\n","            WHERE\n","                rt.task_id NOT IN (SELECT task_id FROM wbs.wbs_task_map)\n","            \"\"\"\n","            return pd.read_sql(query, self.engine)\n","\n","    def generate_embeddings(self, texts):\n","        \"\"\"Generate embeddings for a list of texts\"\"\"\n","        embeddings = []\n","\n","        # Process in batches of 100\n","        batch_size = 100\n","        for i in range(0, len(texts), batch_size):\n","            batch = texts[i:i+batch_size]\n","            response = self.client.embeddings.create(\n","                model=self.embedding_model,\n","                input=batch\n","            )\n","            batch_embeddings = [item.embedding for item in response.data]\n","            embeddings.extend(batch_embeddings)\n","\n","        return embeddings\n","\n","    def prepare_service_catalog_embeddings(self):\n","        \"\"\"Prepare and cache service catalog embeddings\"\"\"\n","        # Fetch service catalog data\n","        catalog_df = self.fetch_service_catalog()\n","\n","        # Create rich text representation for embedding\n","        catalog_df['embedding_text'] = catalog_df.apply(\n","            lambda row: f\"Classification: {row['classification_name']}\\nCategory: {row['category_name']}\\nSubcategory: {row['subcategory_name']}\\nDescription: {row['subcategory_description']}\",\n","            axis=1\n","        )\n","\n","        # Generate embeddings\n","        logging.info(f\"Generating embeddings for {len(catalog_df)} service catalog items\")\n","        catalog_df['embedding'] = self.generate_embeddings(catalog_df['embedding_text'].tolist())\n","\n","        return catalog_df\n","\n","    def prepare_task_embeddings(self, tasks_df):\n","        \"\"\"Prepare embeddings for tasks\"\"\"\n","        logging.info(f\"Generating embeddings for {len(tasks_df)} tasks\")\n","        tasks_df['embedding'] = self.generate_embeddings(tasks_df['task_text'].tolist())\n","        return tasks_df\n","\n","    def find_matching_capabilities(self, task_df, catalog_df, top_n=5, similarity_threshold=0.65):\n","        \"\"\"Find matching capabilities for each task using vector similarity\"\"\"\n","        results = []\n","\n","        for _, task in task_df.iterrows():\n","            task_embedding = np.array(task['embedding'])\n","\n","            # Calculate similarity with all catalog items\n","            similarities = []\n","            for _, catalog_item in catalog_df.iterrows():\n","                catalog_embedding = np.array(catalog_item['embedding'])\n","                similarity = cosine_similarity([task_embedding], [catalog_embedding])[0][0]\n","                similarities.append({\n","                    'subcategory_id': catalog_item['subcategory_id'],\n","                    'subcategory_name': catalog_item['subcategory_name'],\n","                    'classification_name': catalog_item['classification_name'],\n","                    'category_name': catalog_item['category_name'],\n","                    'similarity': similarity\n","                })\n","\n","            # Sort by similarity and get top N\n","            similarities.sort(key=lambda x: x['similarity'], reverse=True)\n","            top_matches = similarities[:top_n]\n","\n","            # Filter by threshold\n","            top_matches = [match for match in top_matches if match['similarity'] >= similarity_threshold]\n","\n","            # Add to results\n","            for match in top_matches:\n","                results.append({\n","                    'task_id': task['task_id'],\n","                    'task_text': task['task_text'],\n","                    'subcategory_id': match['subcategory_id'],\n","                    'subcategory_name': match['subcategory_name'],\n","                    'classification_name': match['classification_name'],\n","                    'category_name': match['category_name'],\n","                    'similarity': match['similarity']\n","                })\n","\n","        return pd.DataFrame(results)\n","\n","    def validate_matches_with_llm(self, matches_df, catalog_df):\n","        \"\"\"Validate matches using LLM to determine confidence\"\"\"\n","        validated_matches = []\n","\n","        # Group by task_id to process all potential matches for a task together\n","        for task_id, group in matches_df.groupby('task_id'):\n","            task_text = group['task_text'].iloc[0]\n","\n","            # Prepare context for LLM\n","            subcategory_contexts = []\n","            for _, match in group.iterrows():\n","                subcategory_id = match['subcategory_id']\n","                catalog_item = catalog_df[catalog_df['subcategory_id'] == subcategory_id].iloc[0]\n","\n","                subcategory_context = {\n","                    'subcategory_id': subcategory_id,\n","                    'subcategory_name': match['subcategory_name'],\n","                    'subcategory_description': catalog_item['subcategory_description'],\n","                    'classification_name': match['classification_name'],\n","                    'category_name': match['category_name'],\n","                    'similarity': match['similarity']\n","                }\n","                subcategory_contexts.append(subcategory_context)\n","\n","            # Create prompt for LLM\n","            prompt = self._create_validation_prompt(task_text, subcategory_contexts)\n","\n","            # Get LLM response\n","            response = self.client.chat.completions.create(\n","                model=self.llm_model,\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"You are an expert in matching government contract requirements to service capabilities.\"},\n","                    {\"role\": \"user\", \"content\": prompt}\n","                ],\n","                temperature=0.2\n","            )\n","\n","            # Parse LLM response\n","            try:\n","                llm_response = response.choices[0].message.content\n","                validated_results = self._parse_llm_validation(llm_response, task_id, task_text, subcategory_contexts)\n","                validated_matches.extend(validated_results)\n","            except Exception as e:\n","                logging.error(f\"Error parsing LLM response for task {task_id}: {e}\")\n","\n","        return pd.DataFrame(validated_matches)\n","\n","    def _create_validation_prompt(self, task_text, subcategory_contexts):\n","        \"\"\"Create prompt for LLM validation\"\"\"\n","        prompt = f\"\"\"Task: {task_text}\n","\n","Potential matching service capabilities:\n","\n","\"\"\"\n","        for i, context in enumerate(subcategory_contexts, 1):\n","            prompt += f\"\"\"Match {i}:\n","- Subcategory: {context['subcategory_name']}\n","- Description: {context['subcategory_description']}\n","- Classification: {context['classification_name']}\n","- Category: {context['category_name']}\n","- Initial similarity score: {context['similarity']:.2f}\n","\n","\"\"\"\n","\n","        prompt += \"\"\"For each potential match, evaluate if the task truly requires this capability. Provide:\n","1. A confidence score (0-100%)\n","2. Brief reasoning for your score\n","\n","Return your evaluation in this format:\n","Match 1: [Subcategory ID] | Confidence: [0-100%] | Reasoning: [brief explanation]\n","Match 2: [Subcategory ID] | Confidence: [0-100%] | Reasoning: [brief explanation]\n","...and so on.\n","\n","Only include matches with confidence score >= 70%.\n","\"\"\"\n","        return prompt\n","\n","    def _parse_llm_validation(self, llm_response, task_id, task_text, subcategory_contexts):\n","        \"\"\"Parse LLM validation response\"\"\"\n","        validated_matches = []\n","        lines = llm_response.strip().split('\\n')\n","\n","        for line in lines:\n","            if '|' not in line:\n","                continue\n","\n","            try:\n","                # Extract subcategory_id, confidence, and reasoning\n","                parts = line.split('|')\n","                match_part = parts[0].strip()\n","                confidence_part = parts[1].strip()\n","                reasoning_part = parts[2].strip() if len(parts) > 2 else \"\"\n","\n","                # Extract subcategory_id\n","                subcategory_id = None\n","                for context in subcategory_contexts:\n","                    if str(context['subcategory_id']) in match_part:\n","                        subcategory_id = context['subcategory_id']\n","                        break\n","\n","                if not subcategory_id:\n","                    continue\n","\n","                # Extract confidence score\n","                confidence_text = confidence_part.replace('Confidence:', '').strip()\n","                confidence = float(confidence_text.replace('%', '')) / 100\n","\n","                # Extract reasoning\n","                reasoning = reasoning_part.replace('Reasoning:', '').strip()\n","\n","                # Only include if confidence >= 0.7\n","                if confidence >= 0.7:\n","                    validated_matches.append({\n","                        'task_id': task_id,\n","                        'task_text': task_text,\n","                        'subcategory_id': subcategory_id,\n","                        'confidence': confidence,\n","                        'reasoning': reasoning\n","                    })\n","            except Exception as e:\n","                logging.error(f\"Error parsing line '{line}': {e}\")\n","\n","        return validated_matches\n","\n","    def store_task_capability_mappings(self, validated_matches_df):\n","        \"\"\"Store validated matches in wbs_task_map table\"\"\"\n","        if validated_matches_df.empty:\n","            logging.info(\"No validated matches to store\")\n","            return 0\n","\n","        # Prepare data for insertion\n","        mappings = []\n","        for _, match in validated_matches_df.iterrows():\n","            mappings.append({\n","                'task_id': match['task_id'],\n","                'capability_id': match['subcategory_id'],\n","                'contractor_performing': None  # This would be set later when a contract is won\n","            })\n","\n","        # Convert to DataFrame\n","        mappings_df = pd.DataFrame(mappings)\n","\n","        # Insert into database\n","        try:\n","            mappings_df.to_sql('wbs_task_map', self.engine, schema='wbs', if_exists='append', index=False)\n","            logging.info(f\"Successfully stored {len(mappings_df)} task-capability mappings\")\n","            return len(mappings_df)\n","        except Exception as e:\n","            logging.error(f\"Error storing task-capability mappings: {e}\")\n","            return 0\n","\n","    def identify_capability_gaps(self, tasks_df, validated_matches_df):\n","        \"\"\"Identify tasks with no high-confidence matches\"\"\"\n","        matched_task_ids = validated_matches_df['task_id'].unique()\n","        unmatched_tasks = tasks_df[~tasks_df['task_id'].isin(matched_task_ids)]\n","\n","        if not unmatched_tasks.empty:\n","            logging.info(f\"Found {len(unmatched_tasks)} tasks with no high-confidence capability matches\")\n","            return unmatched_tasks\n","        else:\n","            logging.info(\"All tasks have been matched to capabilities\")\n","            return pd.DataFrame()\n","\n","    async def process_rfq(self, rfq_id=None):\n","        \"\"\"Process an RFQ to map tasks to capabilities\"\"\"\n","        # Step 1: Fetch and prepare data\n","        logging.info(\"Fetching service catalog data\")\n","        catalog_df = self.prepare_service_catalog_embeddings()\n","\n","        logging.info(\"Fetching RFQ tasks\")\n","        tasks_df = self.fetch_rfq_tasks(rfq_id)\n","\n","        if tasks_df.empty:\n","            logging.info(\"No unmapped tasks found for processing\")\n","            return 0\n","\n","        logging.info(f\"Processing {len(tasks_df)} tasks\")\n","        tasks_df = self.prepare_task_embeddings(tasks_df)\n","\n","        # Step 2: Find matching capabilities using vector similarity\n","        logging.info(\"Finding matching capabilities\")\n","        matches_df = self.find_matching_capabilities(tasks_df, catalog_df)\n","\n","        if matches_df.empty:\n","            logging.info(\"No initial matches found\")\n","            return 0\n","\n","        # Step 3: Validate matches using LLM\n","        logging.info(\"Validating matches with LLM\")\n","        validated_matches_df = self.validate_matches_with_llm(matches_df, catalog_df)\n","\n","        # Step 4: Store validated matches\n","        num_stored = self.store_task_capability_mappings(validated_matches_df)\n","\n","        # Step 5: Identify capability gaps\n","        gaps_df = self.identify_capability_gaps(tasks_df, validated_matches_df)\n","        if not gaps_df.empty:\n","            logging.info(\"Capability gaps identified. Consider reviewing these tasks manually.\")\n","\n","        return num_stored\n","\n","# Main execution\n","async def main():\n","    # Configuration\n","    config = {\n","        \"db_config\": {\n","            \"host\": \"advantantus-prod.cmfo86w02i47.us-east-1.rds.amazonaws.com\",\n","            \"port\": \"5432\",\n","            \"dbname\": \"postgres\",\n","            \"user\": \"postgres\",\n","            \"password\": \"dG1RWVzD!F4YaneD$$\"\n","        },\n","        \"openai_api_key\": \"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\"\n","    }\n","\n","    # Initialize mapper\n","    mapper = TaskCapabilityMapper(config[\"db_config\"], config[\"openai_api_key\"])\n","\n","    # Process all unmapped tasks or specify an RFQ ID\n","    rfq_id = None  # Set to a specific RFQ ID if needed\n","    num_mapped = await mapper.process_rfq(rfq_id)\n","\n","    logging.info(f\"Successfully mapped {num_mapped} tasks to capabilities\")\n","\n","if __name__ == \"__main__\":\n","    asyncio.run(main())\n","else:\n","    # For Jupyter notebook\n","    logging.info(\"Ready to run in Jupyter notebook\")\n"],"metadata":{"id":"BkWBAJMFJHye","executionInfo":{"status":"error","timestamp":1746123295336,"user_tz":240,"elapsed":13562,"user":{"displayName":"David Scott","userId":"14102935354004324335"}},"outputId":"274dfe8a-4e63-4bc7-8d1d-5f73834bd623","colab":{"base_uri":"https://localhost:8080/","height":346}},"execution_count":1,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"asyncio.run() cannot be called from a running event loop","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9cf2fc611102>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;31m# For Jupyter notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# fail fast with short traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1aSfkxn-qll6jSmKGnm0ZYwxa-0m_Z5YC","timestamp":1736965884720},{"file_id":"1MTEes5Pg1gG9vFWNLZHQSkvVCZSJ18fJ","timestamp":1721921977471},{"file_id":"1Nt3oUy5wzTxxx7tnAPPkdYPbiOY-GWd-","timestamp":1719952770966},{"file_id":"1pe5jBrugYlJZg_dka48Ap-uAzejTzPcl","timestamp":1719836665060},{"file_id":"1NMmbgrnZWuu6Zfo2rh7T_ElqfR9ZT4Sg","timestamp":1711048919448},{"file_id":"1xoGd_VXQHl0krbMvYcPInHWmUn4hSK7y","timestamp":1709671785742},{"file_id":"1ic00fCnFiptd_GEnThHbTeaanJItqnoC","timestamp":1708449146973}],"authorship_tag":"ABX9TyO62dPKkzZ4BDndvV5vXdze"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}